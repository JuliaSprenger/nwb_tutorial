{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosyne 2019 NWB:N Tutorial - Extracellular Electrophysiology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this tutorial, we will create fake data for a hypothetical extracellular electrophysiology experiment with a freely moving animal. The types of data we will convert are:\n",
    "- Animal position\n",
    "- LFP\n",
    "- Spike times\n",
    "- Trials\n",
    "- Subject (species, strain, age, etc.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing PyNWB\n",
    "If you are in the tutorial using DANDI Hub, PyNWB is already installed. \n",
    "If participating from your own machine, install PyNWB using pip or conda:\n",
    "- `pip install pynwb`\n",
    "- `conda install -c conda-forge pynwb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the NWB file\n",
    "An NWB file represents a single session of an experiment. Each file must have a session description, identifier, and session start time. Create a new `NWBFile` object with those and additional metadata. For all PyNWB constructors, we recommend using keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBFile\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "start_time = datetime(2018, 4, 25, 2, 30, 3, tzinfo=tz.gettz('US/Pacific'))\n",
    "\n",
    "nwb = NWBFile(session_description='Mouse exploring an open field',\n",
    "              identifier='Mouse5_Day3',\n",
    "              session_start_time=start_time,\n",
    "              session_id='session_1234',                                # optional\n",
    "              experimenter='My Name',                                   # optional\n",
    "              lab='My Lab Name',                                        # optional\n",
    "              institution='University of My Institution',               # optional\n",
    "              related_publications='DOI:10.1016/j.neuron.2016.12.011')  # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject information\n",
    "Create a `Subject` object to store information about the experimental subject, such as age, species, genotype, sex, and a freeform description. And set `nwb.subject` to the `Subject` object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/subject_diagram.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb.file import Subject\n",
    "\n",
    "nwb.subject = Subject(age='9 months', \n",
    "                      description='mouse 5',\n",
    "                      species='Mus musculus', \n",
    "                      sex='M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpatialSeries\n",
    "`SpatialSeries` subclasses `TimeSeries`, which is a common base class for measurements sampled over time.\n",
    "\n",
    "<img src=\"images/spatial_series.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position\n",
    "The `Position` object is a special type of object called a `MultiContainerInterface`. It holds one or more `SpatialSeries` objects. Here, we put a `SpatialSeries` object called `'position'` in a `Position` object, and put that in a `ProcessingModule` named `'behavior'`.\n",
    "\n",
    "<img src=\"images/position.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a new `SpatialSeries object with some arbitrary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pynwb.behavior import SpatialSeries, Position\n",
    "\n",
    "position_data = np.array([np.linspace(0, 10, 100),\n",
    "                          np.linspace(1, 8, 100)]).T\n",
    "spatial_series_object = SpatialSeries(\n",
    "    name='position', \n",
    "    data=position_data,\n",
    "    reference_frame='unknown',\n",
    "    timestamps=np.linspace(0, 100) / 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a `Position` object which contains the `SpatialSeries` object you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_obj = Position(spatial_series=spatial_series_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a new processing module named `'behavior'` in the NWB file and add the `Position` object to the processing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_module = nwbfile.create_processing_module(\n",
    "    name='behavior',\n",
    "    description='processed behavioral data')\n",
    "\n",
    "behavior_module.add_data_interface(pos_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\users\\ryan\\documents\\nwb\\hdmf\\src\\hdmf\\spec\\namespace.py(98)version()\n",
      "-> return self.get('version', None) or SpecNamespace.UNVERSIONED\n"
     ]
    }
   ],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "with NWBHDF5IO('test_ephys.nwb', 'w') as io:\n",
    "    io.write(nwbfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials\n",
    "Trials is another `DynamicTable` that lives an `/intervals/trials`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.add_trial_column('correct', description='correct trial')\n",
    "nwbfile.add_trial(start_time=1.0, stop_time=5.0, correct=True)\n",
    "nwbfile.add_trial(start_time=6.0, stop_time=10.0, correct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electrodes table\n",
    "Extracellular electrodes are stored in a `electrodes`, which is a `DynamicTable`. `electrodes` has several required fields: x, y, z, impedence, location, filtering, and electrode_group. Here, we also demonstate how to add optional columns to a table by adding the `'label'` column.<img src=\"images/electrodes_table.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.add_electrode_column('label', 'label of electrode')\n",
    "shank_channels = [4, 3]\n",
    "\n",
    "electrode_counter = 0\n",
    "device = nwbfile.create_device('implant')\n",
    "for shankn, nelecs in enumerate(shank_channels):\n",
    "    electrode_group = nwbfile.create_electrode_group(\n",
    "       name='shank{}'.format(shankn),\n",
    "       description='electrode group for shank {}'.format(shankn),\n",
    "       device=device,\n",
    "       location='brain area')\n",
    "    for ielec in range(nelecs):\n",
    "        nwbfile.add_electrode(\n",
    "           x=5.3, y=1.5, z=8.5, imp=np.nan,\n",
    "           location='unknown', filtering='unknown',\n",
    "           group=electrode_group,\n",
    "           label='shank{}elec{}'.format(shankn, ielec))\n",
    "        electrode_counter += 1\n",
    "\n",
    "all_table_region = nwbfile.create_electrode_table_region(\n",
    "  list(range(electrode_counter)), 'all electrodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFP\n",
    "`LFP` is another `MultiContainerInterface`. It holds one or more `ElectricalSeries` objects, which are `TimeSeries`. Here, we put an `ElectricalSeries` named `'lfp'` in an `LFP` object, in a `ProcessingModule` named `'ecephys'`.\n",
    "<img src=\"images/lfp.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb.ecephys import ElectricalSeries, LFP\n",
    "lfp_data = np.random.randn(100, 7)\n",
    "ecephys_module = nwbfile.create_processing_module(\n",
    "    name='ecephys',\n",
    "    description='extracellular electrophysiology data')\n",
    "ecephys_module.add_data_interface(\n",
    "LFP(ElectricalSeries('lfp', lfp_data, all_table_region, \n",
    "rate=1000., resolution=.001, conversion=1.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike Times\n",
    "Spike times are stored in another `DynamicTable` of subtype `Units`. The main `Units` table is at `/units` in the HDF5 file. You can add columns to the `Units` table just like you did for `electrodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shankn, channels in enumerate(shank_channels):\n",
    "    for n_units_per_shank in range(np.random.poisson(lam=5)):\n",
    "        n_spikes = np.random.poisson(lam=10)\n",
    "        spike_times = np.abs(np.random.randn(n_spikes))\n",
    "        nwbfile.add_unit(spike_times=spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and read\n",
    "Data arrays are read passively from the file. That means `TimeSeries.data` does not read the entire data object, but presents an h5py object that can be indexed to read data. Index this array just like a numpy array to read only a specific section of the array, or use the `[:]` operator to read the entire thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "with NWBHDF5IO('test_ephys.nwb', 'w') as io:\n",
    "    io.write(nwbfile)\n",
    "\n",
    "with NWBHDF5IO('test_ephys.nwb', 'r') as io:\n",
    "    nwbfile2 = io.read()\n",
    "\n",
    "    print(nwbfile2.modules['ecephys']['LFP'].electrical_series['lfp'].data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing data regions\n",
    "You can easily read subsections of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = NWBHDF5IO('test_ephys.nwb', 'r')\n",
    "nwbfile2 = io.read()\n",
    "\n",
    "print('section of lfp:')\n",
    "print(nwbfile2.modules['ecephys']['LFP'].electrical_series['lfp'].data[:10,:5])\n",
    "print('')\n",
    "print('')\n",
    "print('spike times from first unit:')\n",
    "print(nwbfile2.units['spike_times'][0])\n",
    "io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
